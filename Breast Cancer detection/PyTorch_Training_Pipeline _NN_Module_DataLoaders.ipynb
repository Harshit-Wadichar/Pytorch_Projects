{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "970b174b-feef-4f69-bb17-42b5c3ee7dea",
   "metadata": {},
   "source": [
    "# model with both nn.module and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4af30994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn  as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1d1e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('breast_cancer_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1535b4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['id','Unnamed: 32'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8c8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "060948c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_train = scalar.fit_transform(X_train)\n",
    "X_test = scalar.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac04d507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287    B\n",
       "422    B\n",
       "550    B\n",
       "244    M\n",
       "77     M\n",
       "      ..\n",
       "532    B\n",
       "465    B\n",
       "498    M\n",
       "505    B\n",
       "324    B\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d698c",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afbcdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c675ff5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d8bb8b",
   "metadata": {},
   "source": [
    "#### numpy to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0c0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test_tensor = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41d133d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7968db70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02bf7c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,features,labels):\n",
    "\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.features[index],self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4af9b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train_tensor,y_train_tensor)\n",
    "test_dataset = CustomDataset(X_test_tensor,y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b30e9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0febd32",
   "metadata": {},
   "source": [
    "## Definition of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b1addb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN(nn.Module):\n",
    "\n",
    "    def __init__(self,num_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(num_features,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,features):\n",
    "        out = self.linear(features)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf27ed",
   "metadata": {},
   "source": [
    "### Important parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e92d8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a50e3",
   "metadata": {},
   "source": [
    "## Training Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb91cfef",
   "metadata": {},
   "source": [
    "### Defining loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13c8df4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function =nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a429c8f0",
   "metadata": {},
   "source": [
    "### Defining optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ece2b7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.9051425457000732\n",
      "Epoch: 1, Loss: 0.652751624584198\n",
      "Epoch: 1, Loss: 0.5163341164588928\n",
      "Epoch: 1, Loss: 0.38070642948150635\n",
      "Epoch: 1, Loss: 0.43664246797561646\n",
      "Epoch: 1, Loss: 0.29627102613449097\n",
      "Epoch: 1, Loss: 0.2924727201461792\n",
      "Epoch: 1, Loss: 0.29155126214027405\n",
      "Epoch: 1, Loss: 0.26526862382888794\n",
      "Epoch: 1, Loss: 0.23895904421806335\n",
      "Epoch: 1, Loss: 0.2778773903846741\n",
      "Epoch: 1, Loss: 0.19465357065200806\n",
      "Epoch: 1, Loss: 0.20477814972400665\n",
      "Epoch: 1, Loss: 0.2943990230560303\n",
      "Epoch: 1, Loss: 0.24538961052894592\n",
      "Epoch: 2, Loss: 0.2183152139186859\n",
      "Epoch: 2, Loss: 0.13443994522094727\n",
      "Epoch: 2, Loss: 0.19861264526844025\n",
      "Epoch: 2, Loss: 0.15668420493602753\n",
      "Epoch: 2, Loss: 0.2278423309326172\n",
      "Epoch: 2, Loss: 0.16470980644226074\n",
      "Epoch: 2, Loss: 0.13725531101226807\n",
      "Epoch: 2, Loss: 0.2230055183172226\n",
      "Epoch: 2, Loss: 0.1405811309814453\n",
      "Epoch: 2, Loss: 0.1563582718372345\n",
      "Epoch: 2, Loss: 0.17712487280368805\n",
      "Epoch: 2, Loss: 0.15882232785224915\n",
      "Epoch: 2, Loss: 0.14863063395023346\n",
      "Epoch: 2, Loss: 0.23252105712890625\n",
      "Epoch: 2, Loss: 0.1311461180448532\n",
      "Epoch: 3, Loss: 0.1412089318037033\n",
      "Epoch: 3, Loss: 0.10879400372505188\n",
      "Epoch: 3, Loss: 0.2050275206565857\n",
      "Epoch: 3, Loss: 0.13235977292060852\n",
      "Epoch: 3, Loss: 0.13089828193187714\n",
      "Epoch: 3, Loss: 0.11046057194471359\n",
      "Epoch: 3, Loss: 0.12205731123685837\n",
      "Epoch: 3, Loss: 0.14919441938400269\n",
      "Epoch: 3, Loss: 0.16235482692718506\n",
      "Epoch: 3, Loss: 0.2142033725976944\n",
      "Epoch: 3, Loss: 0.11891767382621765\n",
      "Epoch: 3, Loss: 0.12715815007686615\n",
      "Epoch: 3, Loss: 0.14550723135471344\n",
      "Epoch: 3, Loss: 0.1244024783372879\n",
      "Epoch: 3, Loss: 0.0894554853439331\n",
      "Epoch: 4, Loss: 0.20190395414829254\n",
      "Epoch: 4, Loss: 0.1219283938407898\n",
      "Epoch: 4, Loss: 0.12064316123723984\n",
      "Epoch: 4, Loss: 0.11772762984037399\n",
      "Epoch: 4, Loss: 0.11090832948684692\n",
      "Epoch: 4, Loss: 0.09998706728219986\n",
      "Epoch: 4, Loss: 0.14883872866630554\n",
      "Epoch: 4, Loss: 0.0791783481836319\n",
      "Epoch: 4, Loss: 0.09628485143184662\n",
      "Epoch: 4, Loss: 0.14959955215454102\n",
      "Epoch: 4, Loss: 0.1374187469482422\n",
      "Epoch: 4, Loss: 0.17265646159648895\n",
      "Epoch: 4, Loss: 0.13339215517044067\n",
      "Epoch: 4, Loss: 0.08058711886405945\n",
      "Epoch: 4, Loss: 0.02138025127351284\n",
      "Epoch: 5, Loss: 0.10214806348085403\n",
      "Epoch: 5, Loss: 0.14389164745807648\n",
      "Epoch: 5, Loss: 0.1169649213552475\n",
      "Epoch: 5, Loss: 0.14082959294319153\n",
      "Epoch: 5, Loss: 0.07870755344629288\n",
      "Epoch: 5, Loss: 0.11154688149690628\n",
      "Epoch: 5, Loss: 0.1414048820734024\n",
      "Epoch: 5, Loss: 0.10586780309677124\n",
      "Epoch: 5, Loss: 0.09803218394517899\n",
      "Epoch: 5, Loss: 0.0762324407696724\n",
      "Epoch: 5, Loss: 0.08103429526090622\n",
      "Epoch: 5, Loss: 0.11766770482063293\n",
      "Epoch: 5, Loss: 0.18674825131893158\n",
      "Epoch: 5, Loss: 0.12292499095201492\n",
      "Epoch: 5, Loss: 0.04300422593951225\n",
      "Epoch: 6, Loss: 0.08576646447181702\n",
      "Epoch: 6, Loss: 0.07691553235054016\n",
      "Epoch: 6, Loss: 0.08537597209215164\n",
      "Epoch: 6, Loss: 0.09917297959327698\n",
      "Epoch: 6, Loss: 0.07449889183044434\n",
      "Epoch: 6, Loss: 0.11474887281656265\n",
      "Epoch: 6, Loss: 0.14547118544578552\n",
      "Epoch: 6, Loss: 0.08391967415809631\n",
      "Epoch: 6, Loss: 0.12394823133945465\n",
      "Epoch: 6, Loss: 0.1159103512763977\n",
      "Epoch: 6, Loss: 0.10757143795490265\n",
      "Epoch: 6, Loss: 0.08682270348072052\n",
      "Epoch: 6, Loss: 0.21710647642612457\n",
      "Epoch: 6, Loss: 0.09420811384916306\n",
      "Epoch: 6, Loss: 0.08007682859897614\n",
      "Epoch: 7, Loss: 0.1357380598783493\n",
      "Epoch: 7, Loss: 0.08765550702810287\n",
      "Epoch: 7, Loss: 0.10678043961524963\n",
      "Epoch: 7, Loss: 0.09832361340522766\n",
      "Epoch: 7, Loss: 0.09239888191223145\n",
      "Epoch: 7, Loss: 0.1597619354724884\n",
      "Epoch: 7, Loss: 0.07068909704685211\n",
      "Epoch: 7, Loss: 0.17227739095687866\n",
      "Epoch: 7, Loss: 0.12263656407594681\n",
      "Epoch: 7, Loss: 0.05362294614315033\n",
      "Epoch: 7, Loss: 0.05018187314271927\n",
      "Epoch: 7, Loss: 0.12527009844779968\n",
      "Epoch: 7, Loss: 0.09390921145677567\n",
      "Epoch: 7, Loss: 0.05430392175912857\n",
      "Epoch: 7, Loss: 0.11003462970256805\n",
      "Epoch: 8, Loss: 0.05761349946260452\n",
      "Epoch: 8, Loss: 0.061180174350738525\n",
      "Epoch: 8, Loss: 0.06733529269695282\n",
      "Epoch: 8, Loss: 0.1200004443526268\n",
      "Epoch: 8, Loss: 0.1344195455312729\n",
      "Epoch: 8, Loss: 0.07019893825054169\n",
      "Epoch: 8, Loss: 0.05590017884969711\n",
      "Epoch: 8, Loss: 0.06453954428434372\n",
      "Epoch: 8, Loss: 0.07468345761299133\n",
      "Epoch: 8, Loss: 0.06530880928039551\n",
      "Epoch: 8, Loss: 0.1609552949666977\n",
      "Epoch: 8, Loss: 0.08527199178934097\n",
      "Epoch: 8, Loss: 0.10445443540811539\n",
      "Epoch: 8, Loss: 0.12364513427019119\n",
      "Epoch: 8, Loss: 0.6396650075912476\n",
      "Epoch: 9, Loss: 0.08331266045570374\n",
      "Epoch: 9, Loss: 0.0433448925614357\n",
      "Epoch: 9, Loss: 0.11320085823535919\n",
      "Epoch: 9, Loss: 0.06419335305690765\n",
      "Epoch: 9, Loss: 0.06621468812227249\n",
      "Epoch: 9, Loss: 0.11083630472421646\n",
      "Epoch: 9, Loss: 0.13227197527885437\n",
      "Epoch: 9, Loss: 0.03163773939013481\n",
      "Epoch: 9, Loss: 0.11134271323680878\n",
      "Epoch: 9, Loss: 0.11907140165567398\n",
      "Epoch: 9, Loss: 0.069959357380867\n",
      "Epoch: 9, Loss: 0.09608642756938934\n",
      "Epoch: 9, Loss: 0.23080912232398987\n",
      "Epoch: 9, Loss: 0.06667303293943405\n",
      "Epoch: 9, Loss: 0.022033020853996277\n",
      "Epoch: 10, Loss: 0.09023182094097137\n",
      "Epoch: 10, Loss: 0.060065511614084244\n",
      "Epoch: 10, Loss: 0.060718268156051636\n",
      "Epoch: 10, Loss: 0.15823794901371002\n",
      "Epoch: 10, Loss: 0.04485315829515457\n",
      "Epoch: 10, Loss: 0.10478425025939941\n",
      "Epoch: 10, Loss: 0.058630455285310745\n",
      "Epoch: 10, Loss: 0.11140074580907822\n",
      "Epoch: 10, Loss: 0.2465425282716751\n",
      "Epoch: 10, Loss: 0.0737035870552063\n",
      "Epoch: 10, Loss: 0.10048632323741913\n",
      "Epoch: 10, Loss: 0.05002034828066826\n",
      "Epoch: 10, Loss: 0.06773155182600021\n",
      "Epoch: 10, Loss: 0.07210232317447662\n",
      "Epoch: 10, Loss: 0.007031531073153019\n",
      "Epoch: 11, Loss: 0.12776798009872437\n",
      "Epoch: 11, Loss: 0.05043230205774307\n",
      "Epoch: 11, Loss: 0.11871352791786194\n",
      "Epoch: 11, Loss: 0.02393055148422718\n",
      "Epoch: 11, Loss: 0.09651387482881546\n",
      "Epoch: 11, Loss: 0.09280362725257874\n",
      "Epoch: 11, Loss: 0.047422830015420914\n",
      "Epoch: 11, Loss: 0.1376442313194275\n",
      "Epoch: 11, Loss: 0.08331392705440521\n",
      "Epoch: 11, Loss: 0.1784510463476181\n",
      "Epoch: 11, Loss: 0.039300769567489624\n",
      "Epoch: 11, Loss: 0.07466313987970352\n",
      "Epoch: 11, Loss: 0.07278314232826233\n",
      "Epoch: 11, Loss: 0.11231205612421036\n",
      "Epoch: 11, Loss: 0.04153208062052727\n",
      "Epoch: 12, Loss: 0.06286662817001343\n",
      "Epoch: 12, Loss: 0.0883941501379013\n",
      "Epoch: 12, Loss: 0.13896527886390686\n",
      "Epoch: 12, Loss: 0.225905179977417\n",
      "Epoch: 12, Loss: 0.07667941600084305\n",
      "Epoch: 12, Loss: 0.09820008277893066\n",
      "Epoch: 12, Loss: 0.09396973997354507\n",
      "Epoch: 12, Loss: 0.029533570632338524\n",
      "Epoch: 12, Loss: 0.11174699664115906\n",
      "Epoch: 12, Loss: 0.09258078783750534\n",
      "Epoch: 12, Loss: 0.06726820021867752\n",
      "Epoch: 12, Loss: 0.04681393876671791\n",
      "Epoch: 12, Loss: 0.04687359929084778\n",
      "Epoch: 12, Loss: 0.025968680158257484\n",
      "Epoch: 12, Loss: 0.11860637366771698\n",
      "Epoch: 13, Loss: 0.044999461621046066\n",
      "Epoch: 13, Loss: 0.07144688814878464\n",
      "Epoch: 13, Loss: 0.05703116953372955\n",
      "Epoch: 13, Loss: 0.0307356808334589\n",
      "Epoch: 13, Loss: 0.08041746914386749\n",
      "Epoch: 13, Loss: 0.1112818717956543\n",
      "Epoch: 13, Loss: 0.07930900901556015\n",
      "Epoch: 13, Loss: 0.12178272753953934\n",
      "Epoch: 13, Loss: 0.08049968630075455\n",
      "Epoch: 13, Loss: 0.10547085106372833\n",
      "Epoch: 13, Loss: 0.21926772594451904\n",
      "Epoch: 13, Loss: 0.039159707725048065\n",
      "Epoch: 13, Loss: 0.058346010744571686\n",
      "Epoch: 13, Loss: 0.08708833158016205\n",
      "Epoch: 13, Loss: 0.07926495373249054\n",
      "Epoch: 14, Loss: 0.10191824287176132\n",
      "Epoch: 14, Loss: 0.0878015011548996\n",
      "Epoch: 14, Loss: 0.11027765274047852\n",
      "Epoch: 14, Loss: 0.04527212306857109\n",
      "Epoch: 14, Loss: 0.16577936708927155\n",
      "Epoch: 14, Loss: 0.10610136389732361\n",
      "Epoch: 14, Loss: 0.06089787185192108\n",
      "Epoch: 14, Loss: 0.10157907754182816\n",
      "Epoch: 14, Loss: 0.06022574007511139\n",
      "Epoch: 14, Loss: 0.08767777681350708\n",
      "Epoch: 14, Loss: 0.022642988711595535\n",
      "Epoch: 14, Loss: 0.06803084909915924\n",
      "Epoch: 14, Loss: 0.08733569830656052\n",
      "Epoch: 14, Loss: 0.06489972770214081\n",
      "Epoch: 14, Loss: 0.04273796081542969\n",
      "Epoch: 15, Loss: 0.06313981115818024\n",
      "Epoch: 15, Loss: 0.21376068890094757\n",
      "Epoch: 15, Loss: 0.06683512032032013\n",
      "Epoch: 15, Loss: 0.08819220960140228\n",
      "Epoch: 15, Loss: 0.04862493649125099\n",
      "Epoch: 15, Loss: 0.0572831928730011\n",
      "Epoch: 15, Loss: 0.057425398379564285\n",
      "Epoch: 15, Loss: 0.05599813535809517\n",
      "Epoch: 15, Loss: 0.0957670509815216\n",
      "Epoch: 15, Loss: 0.0527658648788929\n",
      "Epoch: 15, Loss: 0.07031725347042084\n",
      "Epoch: 15, Loss: 0.09506326913833618\n",
      "Epoch: 15, Loss: 0.07996122539043427\n",
      "Epoch: 15, Loss: 0.09863968193531036\n",
      "Epoch: 15, Loss: 0.04852912202477455\n",
      "Epoch: 16, Loss: 0.04123793542385101\n",
      "Epoch: 16, Loss: 0.035041917115449905\n",
      "Epoch: 16, Loss: 0.11464565247297287\n",
      "Epoch: 16, Loss: 0.113832987844944\n",
      "Epoch: 16, Loss: 0.04042118415236473\n",
      "Epoch: 16, Loss: 0.09019894152879715\n",
      "Epoch: 16, Loss: 0.19475290179252625\n",
      "Epoch: 16, Loss: 0.05155887454748154\n",
      "Epoch: 16, Loss: 0.09375911951065063\n",
      "Epoch: 16, Loss: 0.0696147084236145\n",
      "Epoch: 16, Loss: 0.10958500951528549\n",
      "Epoch: 16, Loss: 0.0790020227432251\n",
      "Epoch: 16, Loss: 0.022483564913272858\n",
      "Epoch: 16, Loss: 0.046031784266233444\n",
      "Epoch: 16, Loss: 0.15282849967479706\n",
      "Epoch: 17, Loss: 0.05786825716495514\n",
      "Epoch: 17, Loss: 0.05047892779111862\n",
      "Epoch: 17, Loss: 0.12814617156982422\n",
      "Epoch: 17, Loss: 0.06833597272634506\n",
      "Epoch: 17, Loss: 0.020024843513965607\n",
      "Epoch: 17, Loss: 0.04820191115140915\n",
      "Epoch: 17, Loss: 0.02591918781399727\n",
      "Epoch: 17, Loss: 0.055346790701150894\n",
      "Epoch: 17, Loss: 0.07099579274654388\n",
      "Epoch: 17, Loss: 0.08825541287660599\n",
      "Epoch: 17, Loss: 0.08045592159032822\n",
      "Epoch: 17, Loss: 0.09607963263988495\n",
      "Epoch: 17, Loss: 0.07800683379173279\n",
      "Epoch: 17, Loss: 0.220648393034935\n",
      "Epoch: 17, Loss: 0.12387903779745102\n",
      "Epoch: 18, Loss: 0.036931924521923065\n",
      "Epoch: 18, Loss: 0.08264331519603729\n",
      "Epoch: 18, Loss: 0.15907590091228485\n",
      "Epoch: 18, Loss: 0.09679843485355377\n",
      "Epoch: 18, Loss: 0.10740667581558228\n",
      "Epoch: 18, Loss: 0.14117375016212463\n",
      "Epoch: 18, Loss: 0.11372930556535721\n",
      "Epoch: 18, Loss: 0.03963758423924446\n",
      "Epoch: 18, Loss: 0.04928898811340332\n",
      "Epoch: 18, Loss: 0.05494808033108711\n",
      "Epoch: 18, Loss: 0.06350721418857574\n",
      "Epoch: 18, Loss: 0.031826358288526535\n",
      "Epoch: 18, Loss: 0.0559210479259491\n",
      "Epoch: 18, Loss: 0.025316571816802025\n",
      "Epoch: 18, Loss: 0.18046629428863525\n",
      "Epoch: 19, Loss: 0.06273095309734344\n",
      "Epoch: 19, Loss: 0.07926575839519501\n",
      "Epoch: 19, Loss: 0.10317514836788177\n",
      "Epoch: 19, Loss: 0.07808581739664078\n",
      "Epoch: 19, Loss: 0.10785751044750214\n",
      "Epoch: 19, Loss: 0.03856281936168671\n",
      "Epoch: 19, Loss: 0.21165400743484497\n",
      "Epoch: 19, Loss: 0.0708267018198967\n",
      "Epoch: 19, Loss: 0.05095675587654114\n",
      "Epoch: 19, Loss: 0.06450448930263519\n",
      "Epoch: 19, Loss: 0.06803533434867859\n",
      "Epoch: 19, Loss: 0.03451872617006302\n",
      "Epoch: 19, Loss: 0.04539948329329491\n",
      "Epoch: 19, Loss: 0.06372493505477905\n",
      "Epoch: 19, Loss: 0.02006096951663494\n",
      "Epoch: 20, Loss: 0.05964122712612152\n",
      "Epoch: 20, Loss: 0.07432647794485092\n",
      "Epoch: 20, Loss: 0.05017075315117836\n",
      "Epoch: 20, Loss: 0.07543304562568665\n",
      "Epoch: 20, Loss: 0.04327408969402313\n",
      "Epoch: 20, Loss: 0.044282346963882446\n",
      "Epoch: 20, Loss: 0.055773403495550156\n",
      "Epoch: 20, Loss: 0.08813900500535965\n",
      "Epoch: 20, Loss: 0.08541203290224075\n",
      "Epoch: 20, Loss: 0.21497757732868195\n",
      "Epoch: 20, Loss: 0.020276449620723724\n",
      "Epoch: 20, Loss: 0.07976991683244705\n",
      "Epoch: 20, Loss: 0.051670175045728683\n",
      "Epoch: 20, Loss: 0.10765261948108673\n",
      "Epoch: 20, Loss: 0.08727362006902695\n",
      "Epoch: 21, Loss: 0.045349884778261185\n",
      "Epoch: 21, Loss: 0.1307561695575714\n",
      "Epoch: 21, Loss: 0.031208962202072144\n",
      "Epoch: 21, Loss: 0.03620998561382294\n",
      "Epoch: 21, Loss: 0.039019808173179626\n",
      "Epoch: 21, Loss: 0.06282396614551544\n",
      "Epoch: 21, Loss: 0.025918185710906982\n",
      "Epoch: 21, Loss: 0.09488998353481293\n",
      "Epoch: 21, Loss: 0.06583817303180695\n",
      "Epoch: 21, Loss: 0.0806775838136673\n",
      "Epoch: 21, Loss: 0.2133232206106186\n",
      "Epoch: 21, Loss: 0.0708746612071991\n",
      "Epoch: 21, Loss: 0.04487529769539833\n",
      "Epoch: 21, Loss: 0.1102311983704567\n",
      "Epoch: 21, Loss: 0.024256525561213493\n",
      "Epoch: 22, Loss: 0.10718762874603271\n",
      "Epoch: 22, Loss: 0.03768086060881615\n",
      "Epoch: 22, Loss: 0.07919999957084656\n",
      "Epoch: 22, Loss: 0.05562084913253784\n",
      "Epoch: 22, Loss: 0.18043136596679688\n",
      "Epoch: 22, Loss: 0.039853986352682114\n",
      "Epoch: 22, Loss: 0.08225146681070328\n",
      "Epoch: 22, Loss: 0.08365754783153534\n",
      "Epoch: 22, Loss: 0.028800420463085175\n",
      "Epoch: 22, Loss: 0.09265498071908951\n",
      "Epoch: 22, Loss: 0.059994012117385864\n",
      "Epoch: 22, Loss: 0.06419095396995544\n",
      "Epoch: 22, Loss: 0.04420121759176254\n",
      "Epoch: 22, Loss: 0.08735962212085724\n",
      "Epoch: 22, Loss: 0.011396254412829876\n",
      "Epoch: 23, Loss: 0.08254285156726837\n",
      "Epoch: 23, Loss: 0.0890800878405571\n",
      "Epoch: 23, Loss: 0.19513121247291565\n",
      "Epoch: 23, Loss: 0.04267880693078041\n",
      "Epoch: 23, Loss: 0.06811796128749847\n",
      "Epoch: 23, Loss: 0.09608365595340729\n",
      "Epoch: 23, Loss: 0.05499069392681122\n",
      "Epoch: 23, Loss: 0.02509133145213127\n",
      "Epoch: 23, Loss: 0.01453816331923008\n",
      "Epoch: 23, Loss: 0.0986996442079544\n",
      "Epoch: 23, Loss: 0.12265832722187042\n",
      "Epoch: 23, Loss: 0.050412867218256\n",
      "Epoch: 23, Loss: 0.03844071924686432\n",
      "Epoch: 23, Loss: 0.053035952150821686\n",
      "Epoch: 23, Loss: 0.010269047692418098\n",
      "Epoch: 24, Loss: 0.19778017699718475\n",
      "Epoch: 24, Loss: 0.18224167823791504\n",
      "Epoch: 24, Loss: 0.02373605966567993\n",
      "Epoch: 24, Loss: 0.06977877765893936\n",
      "Epoch: 24, Loss: 0.06799865514039993\n",
      "Epoch: 24, Loss: 0.05839172378182411\n",
      "Epoch: 24, Loss: 0.07076054811477661\n",
      "Epoch: 24, Loss: 0.0333704948425293\n",
      "Epoch: 24, Loss: 0.053179848939180374\n",
      "Epoch: 24, Loss: 0.04214952141046524\n",
      "Epoch: 24, Loss: 0.06539362668991089\n",
      "Epoch: 24, Loss: 0.04699725657701492\n",
      "Epoch: 24, Loss: 0.06453657895326614\n",
      "Epoch: 24, Loss: 0.04683485999703407\n",
      "Epoch: 24, Loss: 0.0018282808596268296\n",
      "Epoch: 25, Loss: 0.10333720594644547\n",
      "Epoch: 25, Loss: 0.10280510038137436\n",
      "Epoch: 25, Loss: 0.2259145826101303\n",
      "Epoch: 25, Loss: 0.09005190432071686\n",
      "Epoch: 25, Loss: 0.03757523372769356\n",
      "Epoch: 25, Loss: 0.048456091433763504\n",
      "Epoch: 25, Loss: 0.030418116599321365\n",
      "Epoch: 25, Loss: 0.06494809687137604\n",
      "Epoch: 25, Loss: 0.04922451823949814\n",
      "Epoch: 25, Loss: 0.06474005430936813\n",
      "Epoch: 25, Loss: 0.02462170645594597\n",
      "Epoch: 25, Loss: 0.054588720202445984\n",
      "Epoch: 25, Loss: 0.043224308639764786\n",
      "Epoch: 25, Loss: 0.0709981769323349\n",
      "Epoch: 25, Loss: 0.022139115259051323\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = MySimpleNN(X_train_tensor.shape[1])\n",
    "\n",
    "\n",
    "# define optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
    "# define loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for batch_features, batch_labels in train_loader:\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(batch_features)\n",
    "\n",
    "\n",
    "        # loss calculate\n",
    "        loss = loss_function(y_pred,batch_labels.view(-1,1))\n",
    "\n",
    "        # clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "        # print loss in each epochs\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8f79d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.4718,  0.4606,  0.4778,  0.6502,  0.0888,  0.1284,  0.4604,  0.7909,\n",
       "          0.0206, -0.1268,  0.5713, -0.0129,  0.4745,  0.6703,  0.0777, -0.3159,\n",
       "         -0.1516,  0.0618, -0.1251, -0.2356,  0.6279,  0.7192,  0.5925,  0.5587,\n",
       "          0.5978,  0.2545,  0.3975,  0.4988,  0.5728,  0.0842]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f933dd",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4239912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:-> 0.5258541107177734\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model.forward(X_test_tensor)\n",
    "    y_pred = (y_pred > 0.5).float()\n",
    "    accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "    print(f\"Accuracy Score:-> {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf187e40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
